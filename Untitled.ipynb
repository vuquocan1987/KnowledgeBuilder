{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0529778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac2d87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fresh': False,\n",
       " 'iat': 1694454067,\n",
       " 'jti': '5e2e8c34-7ad2-4b59-80da-a48d7ee093da',\n",
       " 'type': 'access',\n",
       " 'sub': 'An',\n",
       " 'nbf': 1694454067,\n",
       " 'exp': 1694454967}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jwt\n",
    "with open(\"public_key.pem\", \"r\") as f:\n",
    "    public_key = f.read()\n",
    "\n",
    "token = \"eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJmcmVzaCI6ZmFsc2UsImlhdCI6MTY5NDQ1NDA2NywianRpIjoiNWUyZThjMzQtN2FkMi00YjU5LTgwZGEtYTQ4ZDdlZTA5M2RhIiwidHlwZSI6ImFjY2VzcyIsInN1YiI6IkFuIiwibmJmIjoxNjk0NDU0MDY3LCJleHAiOjE2OTQ0NTQ5Njd9.b5NeSOU84VRJeEaln67FKjaLZmKcH3SmdQAOtMMRNOClJlEcpGP_vwpe85bebge4pfuYBKMDhUgwhRYGWc8QUxlISgvBDa6i9qMSChCDHWLRkNHlPBj1gjTcfo-vyeBKB3WrtFfRBQsbkccpWznCR7mtQL1aJTDb_YVDnO-E27YH_hBPQ-MZwz_BB5vCpCmgakNvmc4jUT2BGH-yjuwfQi6VzGd4h8nBV3H-Qy29pZrFBOPLmKE8-qCKleDs2vmvXLDYW08ya16BPfADujW1laDLbxS3csA8O0C4QDUHQNTzuwQ3n_QqzFBWbgISl_16LFVN3jbnMDJZsWs5wOPxig\"\n",
    "jwt.decode(token, public_key, algorithms=[\"RS256\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d36750e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a8565f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada691e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e930e26",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "text",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/knowledge/lib/python3.9/site-packages/openai/openai_object.py:59\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[k]\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m key\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     messages\u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mgive me a short joke\u001b[39m\u001b[39m\"\u001b[39m}]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/an/Workspace/KnowledgeBuilder/Untitled.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39;49mchoices[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtext)\n",
      "File \u001b[0;32m~/miniconda3/envs/knowledge/lib/python3.9/site-packages/openai/openai_object.py:61\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[k]\n\u001b[1;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m*\u001b[39merr\u001b[39m.\u001b[39margs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: text"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = key\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages= [{\"role\":\"user\",\"content\":\"give me a short joke\"}]\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "863c0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = key\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"give me a short joke\"},\n",
    "        {\"role\": \"user\", \"content\": \"tell me 1 sentence joke?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ac2052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-86KbnKMOc0dMHCkXS5vSbxvJMcB5h at 0x7f906e34e720> JSON: {\n",
       "  \"id\": \"chatcmpl-86KbnKMOc0dMHCkXS5vSbxvJMcB5h\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1696519879,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Why don't scientists trust atoms?\\nBecause they make up everything!\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 14,\n",
       "    \"completion_tokens\": 13,\n",
       "    \"total_tokens\": 27\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b33f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file yaml\n",
    "import yaml\n",
    "with open(\"CodeGenerator/ServicesList.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67540a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CodeGenerator.PrompConnector import *\n",
    "sers = get_service_specification()\n",
    "promptcreator = SpecificationPromptCreator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d813cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "openai.api_key = key\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": promptcreator.guided_prompt},\n",
    "        {\"role\": \"user\", \"content\": promptcreator.get_output(\"Add a new microservice that is possible to add two numbers\")}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e32061b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-86T9V018VJcsxxNRRzZJPXU6iCdvZ at 0x7f8ab3d6b860> JSON: {\n",
       "  \"id\": \"chatcmpl-86T9V018VJcsxxNRRzZJPXU6iCdvZ\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1696552721,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"import json\\n\\n# New microservice OpenAPI specification\\nnew_microservice_spec = {\\n    'openapi': '3.0.0',\\n    'info': {\\n        'title': 'Addition API',\\n        'version': '1.0.0'\\n    },\\n    'paths': {\\n        '/addition': {\\n            'post': {\\n                'summary': 'Add two numbers',\\n                'requestBody': {\\n                    'content': {\\n                        'application/json': {\\n                            'schema': {\\n                                'type': 'object',\\n                                'properties': {\\n                                    'num1': {'type': 'number'},\\n                                    'num2': {'type': 'number'}\\n                                },\\n                                'required': ['num1', 'num2']\\n                            }\\n                        }\\n                    }\\n                },\\n                'responses': {\\n                    '200': {\\n                        'description': 'Addition successful',\\n                        'content': {\\n                            'application/json': {\\n                                'schema': {\\n                                    'type': 'object',\\n                                    'properties': {\\n                                        'result': {'type': 'number'}\\n                                    }\\n                                }\\n                            }\\n                        }\\n                    }\\n                }\\n            }\\n        }\\n    }\\n}\\n\\n# Create new microservice specification file\\nwith open('addition.yaml', 'w') as f:\\n    f.write(json.dumps(new_microservice_spec))\\n\\n# Print success message\\nprint('New microservice specification file created: addition.yaml')\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 915,\n",
       "    \"completion_tokens\": 283,\n",
       "    \"total_tokens\": 1198\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write the content to the file\n",
    "with open(\"tmp.py\", \"w\") as f:\n",
    "    f.write(response.choices[0].message.content)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5a9623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                On the next prompt I'll outline the specifications of our deployed microservices system and introduce a new requirement for the program. Your task is to provide the OpenAPI specification for a new microservice addition to the cluster.\n",
      "Specifications detail the services active in the cluster. Each service comprises:\n",
      "\n",
      "            Name: Identifying the service.\n",
      "            Description: Elucidating the service's functionality.\n",
      "            OpenAPI Specification: This is the YAML-formatted blueprint of the service. For instance, a login.yaml file suggests two services in the cluster: the login and browsing services.\n",
      "            Deployment Specification: How the service is deployed.\n",
      "            Prometheus Specification: Monitoring parameters for the service.\n",
      "            Service Specification: How the service is accessed and related configurations.\n",
      "The new requirement will be expressed in plain language. For example, \"Introduce a service that adds two numbers.\" Based on the existing system and new requirements, your role is to adapt and provide the updated OpenAPI specification for the new service.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(promptcreator.guided_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "App",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
